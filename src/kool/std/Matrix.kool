package kool.std

var m = new Matrix<Int>(5)
println(m)

class Matrix<T> {

    var rows: Int
    var columns: Int
    var data: MatrixRow<T>[]

    Def new(size: Int)               = init(size, size)
    Def new(rows: Int, columns: Int) = init(rows, columns)
    Def implicit new(arrays: T[][]) = {
        if(arrays.length == 0 || arrays[0].length == 0){
            init(0, 0)
            return
        }

        init(arrays.length, arrays[0].length)
        for(var i = 0; i < columns; i++)
           for(var j = 0; j < rows; j++)
               this[i][j] = arrays[i][j]
    }

    Def [](index: Int) = return data[index]
    Def []=(index: Int, row: T[]) = data[index] = new MatrixRow<T>(row)

    Def +(lhs: Matrix<T>, rhs: Matrix<T>) = {
        if(lhs.rows != rhs.rows || lhs.columns != rhs.columns)
            errorInvalidDimensions(lhs, rhs)

        var m = new Matrix<T>(lhs.columns, lhs.rows)
        for(var i = 0; i < m.columns; i++)
            for(var j = 0; j < m.rows; j++)
                m[i][j] = lhs[i][j] + rhs[i][j]

        return m
    }

    Def -(lhs: Matrix<T>, rhs: Matrix<T>) = {
        if(lhs.rows != rhs.rows || lhs.columns != rhs.columns)
            errorInvalidDimensions(lhs, rhs)

        var m = new Matrix<T>(lhs.columns, lhs.rows)
        for(var i = 0; i < m.columns; i++)
            for(var j = 0; j < m.rows; j++)
                m[i][j] = lhs[i][j] - rhs[i][j]

        return m
    }

    Def *(matrix: Matrix<T>, scalar: T) = return scalar * matrix
    Def *(scalar: T, matrix: Matrix<T>) = {
        var m = new Matrix<T>(matrix.columns, matrix.rows)
        for(var i = 0; i < m.columns; i++)
           for(var j = 0; j < m.rows; j++)
                m[i][j] = scalar * matrix[i][j]

        return m
    }

    Def *(lhs: Matrix<T>, rhs: Matrix<T>) = {
        if(lhs.columns != rhs.rows)
            errorInvalidDimensions(lhs, rhs)

        var m = new Matrix<T>(lhs.rows, lhs.columns)
        for(var i = 0; i < m.columns; i++)
            for(var j = 0; j < m.rows; j++)
                for(var k = 0; k < lhs.columns; k++)
                    m[i][j] += lhs[i][k] * rhs[k][j]

        return m
    }

    Def -(matrix: Matrix<T>) = return -1 * matrix

    Def #(matrix: Matrix<T>) = {
        var res: Int
        for(var i = 0; i < matrix.columns; i++)
           for(var j = 0; j < matrix.rows; j++)
               res = 31 * res + #matrix[i][j]

        return res
    }

    Def Transpose(): Matrix<T> = {
        var m = new Matrix<T>(columns, rows)
        for(var i = 0; i < columns; i++)
           for(var j = 0; j < rows; j++)
               m[i][j] = data[j][i]

        return m
    }

    Def Columns() = return columns
    Def Rows() = return rows

    Def toString() = {
        if(columns == 0 || rows == 0)
            return "[]"

        var s = ""
        for(var i = 0; i < rows; i++)
            s += data[i] + "\n"
        return s
    }

    def init(rows: Int, columns: Int) = {
        this.columns = columns
        this.rows = rows
        data = new MatrixRow<T>[rows]
        for(var i = 0; i < rows; i++)
            data[i] = new MatrixRow<T>(columns)
    }

    def static errorInvalidDimensions(m1: Matrix<T>, m2: Matrix<T>) =
        error("Invalid dimensions for matrix operaton: (" + m1.rows + ", " + m1.columns + ") and (" + m2.rows + ", " + m2.columns + ").")
}

class MatrixRow<T> {

    var data: T[]

    Def new(w: Int) = data = new T[w]
    Def new(d: T[]) = data = d

    Def [](index: Int) = return data[index]

    Def []=(index: Int, value: T) = data[index] = value

    Def toString() = {
        if(data.length == 0)
            return "[]"

        var s = "[ "
        for(var i = 0; i < data.length; i++) s += data[i] + " "
        return s + "]"
    }

}